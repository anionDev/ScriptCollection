from datetime import datetime, timedelta, timezone
from graphlib import TopologicalSorter
import os
import argparse
from pathlib import Path
from functools import cmp_to_key
import shutil
import math
import tarfile
import re
import sys
import zipfile
import json
import configparser
import tempfile
import uuid
import yaml
import requests
from packaging import version
import xmlschema
from OpenSSL import crypto
from lxml import etree
from .GeneralUtilities import GeneralUtilities
from .ScriptCollectionCore import ScriptCollectionCore
from .SCLog import SCLog, LogLevel
from .ProgramRunnerEpew import ProgramRunnerEpew
from .ImageUpdater import ImageUpdater, VersionEcholon

#entire file is obsolete and should be replaced by new TFCPS-files


class TasksForCommonProjectStructure:
    __sc: ScriptCollectionCore = None
    reference_latest_version_of_xsd_when_generating_xml: bool = True
    validate_developers_of_repository: bool = True
    dotnet_runsettings_file = "runsettings.xml"
    __log:SCLog=None
    targetenvironmenttype:str
    is_pre_merge:bool
    assume_dependent_codeunits_are_already_built:bool
    additionalargumentsfile:str

    def __init__(self,cmd_arguments:list[str]=[]):
        parser = argparse.ArgumentParser()
        verbosity_values = ", ".join(f"{lvl.value}={lvl.name}" for lvl in LogLevel)
        parser.add_argument('-v', '--verbosity', required=False, default=3, help=f"Sets the loglevel. Possible values: {verbosity_values}")
        parser.add_argument('-e', '--targetenvironmenttype', required=False,default="QualityCheck")
        parser.add_argument('-p', '--is_pre_merge', action='store_true', required=False, default=False)
        parser.add_argument('-b', '--assume_dependent_codeunits_are_already_built',action='store_true', required=False)
        parser.add_argument('-a', '--additionalargumentsfile', required=False,default=None)
        args=parser.parse_args()
        log: SCLog = SCLog()
        log.loglevel = LogLevel(int(args.verbosity))
        sc = ScriptCollectionCore()
        sc.log = log
        self.__sc = sc
        self.__log=sc.log
        self.targetenvironmenttype=args.targetenvironmenttype
        self.is_pre_merge=args.is_pre_merge
        self.assume_dependent_codeunits_are_already_built=args.assume_dependent_codeunits_are_already_built
        self.additionalargumentsfile=args.additionalargumentsfile

    @staticmethod
    @GeneralUtilities.check_arguments
    def get_development_environment_name() -> str:
        return "Development"

    @staticmethod
    @GeneralUtilities.check_arguments
    def get_qualitycheck_environment_name() -> str:
        return "QualityCheck"

    @staticmethod
    @GeneralUtilities.check_arguments
    def get_productive_environment_name() -> str:
        return "Productive"

    @GeneralUtilities.check_arguments
    def get_build_folder(self, repository_folder: str, codeunit_name: str) -> str:
        self.__sc.assert_is_git_repository(repository_folder)
        return os.path.join(repository_folder, codeunit_name, "Other", "Build")

    @GeneralUtilities.check_arguments
    def replace_version_in_python_file(self, file: str, new_version_value: str) -> None:
        GeneralUtilities.write_text_to_file(file, re.sub("version = \"\\d+\\.\\d+\\.\\d+\"", f"version = \"{new_version_value}\"", GeneralUtilities.read_text_from_file(file)))

    @GeneralUtilities.check_arguments
    def standardized_tasks_build_for_dart_project_in_common_project_structure(self, build_script_file: str, targets: list[str], args: list[str], package_name: str = None):
        codeunit_folder = GeneralUtilities.resolve_relative_path("../../..", build_script_file)
        codeunit_name = os.path.basename(codeunit_folder)
        src_folder: str = None
        if package_name is None:
            src_folder = codeunit_folder
        else:
            src_folder = GeneralUtilities.resolve_relative_path(package_name, codeunit_folder)  # TODO replace packagename
        artifacts_folder = os.path.join(codeunit_folder, "Other", "Artifacts")
        
        target_names: dict[str, str] = {
            "web": "WebApplication",
            "windows": "Windows",
            "ios": "IOS",
            "appbundle": "Android",
        }
        for target in targets:
            self.__log.log(f"Build flutter-codeunit {codeunit_name} for target {target_names[target]}...")
            self.run_with_epew("flutter", f"build {target}", src_folder)
            if target == "web":
                web_relase_folder = os.path.join(src_folder, "build/web")
                web_folder = os.path.join(artifacts_folder, "BuildResult_WebApplication")
                GeneralUtilities.ensure_directory_does_not_exist(web_folder)
                GeneralUtilities.ensure_directory_exists(web_folder)
                GeneralUtilities.copy_content_of_folder(web_relase_folder, web_folder)
            elif target == "windows":
                windows_release_folder = os.path.join(src_folder, "build/windows/x64/runner/Release")
                windows_folder = os.path.join(artifacts_folder, "BuildResult_Windows")
                GeneralUtilities.ensure_directory_does_not_exist(windows_folder)
                GeneralUtilities.ensure_directory_exists(windows_folder)
                GeneralUtilities.copy_content_of_folder(windows_release_folder, windows_folder)
            elif target == "ios":
                raise ValueError("building for ios is not implemented yet")
            elif target == "appbundle":
                aab_folder = os.path.join(artifacts_folder, "BuildResult_AAB")
                GeneralUtilities.ensure_directory_does_not_exist(aab_folder)
                GeneralUtilities.ensure_directory_exists(aab_folder)
                aab_relase_folder = os.path.join(src_folder, "build/app/outputs/bundle/release")
                aab_file_original = self.__sc.find_file_by_extension(aab_relase_folder, "aab")
                aab_file = os.path.join(aab_folder, f"{codeunit_name}.aab")
                shutil.copyfile(aab_file_original, aab_file)
                bundletool = os.path.join(codeunit_folder, "Other/Resources/AndroidAppBundleTool/bundletool.jar")
                apk_folder = os.path.join(artifacts_folder, "BuildResult_APK")
                GeneralUtilities.ensure_directory_does_not_exist(apk_folder)
                GeneralUtilities.ensure_directory_exists(apk_folder)
                apks_file = f"{apk_folder}/{codeunit_name}.apks"
                self.__sc.run_program("java", f"-jar {bundletool} build-apks --bundle={aab_file} --output={apks_file} --mode=universal", aab_relase_folder)
                with zipfile.ZipFile(apks_file, "r") as zip_ref:
                    zip_ref.extract("universal.apk", apk_folder)
                GeneralUtilities.ensure_file_does_not_exist(apks_file)
                os.rename(f"{apk_folder}/universal.apk", f"{apk_folder}/{codeunit_name}.apk")
            else:
                raise ValueError(f"Not supported target: {target}")
        self.copy_source_files_to_output_directory(build_script_file)
        #TODO check for updateable dependencies (in a unified way)



    @staticmethod
    @GeneralUtilities.check_arguments
    def get_string_value_from_commandline_arguments(commandline_arguments: list[str], property_name: str, default_value: str) -> str:
        result = TasksForCommonProjectStructure.get_property_from_commandline_arguments(commandline_arguments, property_name)
        if result is None:
            return default_value
        else:
            return result

    @staticmethod
    @GeneralUtilities.check_arguments
    def get_is_pre_merge_value_from_commandline_arguments(commandline_arguments: list[str],  default_value: bool) -> bool:
        result = TasksForCommonProjectStructure.get_property_from_commandline_arguments(commandline_arguments, "is_pre_merge")
        if result is None:
            return default_value
        else:
            return GeneralUtilities.string_to_boolean(result)

    @staticmethod
    @GeneralUtilities.check_arguments
    def get_assume_dependent_codeunits_are_already_built_from_commandline_arguments(commandline_arguments: list[str],  default_value: bool) -> bool:
        result = TasksForCommonProjectStructure.get_property_from_commandline_arguments(commandline_arguments, "assume_dependent_codeunits_are_already_built")
        if result is None:
            return default_value
        else:
            return GeneralUtilities.string_to_boolean(result)

    @staticmethod
    @GeneralUtilities.check_arguments
    def get_verbosity_from_commandline_arguments(commandline_arguments: list[str],  default_value: int) -> LogLevel:
        result = TasksForCommonProjectStructure.get_property_from_commandline_arguments(commandline_arguments, "verbosity")
        if result is None:
            return default_value
        else:
            return LogLevel(int(result))

    @staticmethod
    @GeneralUtilities.check_arguments
    def get_targetenvironmenttype_from_commandline_arguments(commandline_arguments: list[str],  default_value: str) -> str:
        result = TasksForCommonProjectStructure.get_property_from_commandline_arguments(commandline_arguments, "targetenvironmenttype")
        if result is None:
            return default_value
        else:
            return result

    @staticmethod
    @GeneralUtilities.check_arguments
    def get_additionalargumentsfile_from_commandline_arguments(commandline_arguments: list[str],  default_value: str) -> str:
        result = TasksForCommonProjectStructure.get_property_from_commandline_arguments(commandline_arguments, "additionalargumentsfile")
        if result is None:
            return default_value
        else:
            return result

    @staticmethod
    @GeneralUtilities.check_arguments
    def get_property_from_commandline_arguments(commandline_arguments: list[str], property_name: str) -> str:
        result: str = None
        count = len(commandline_arguments)
        loop_index = -1
        for commandline_argument in commandline_arguments:
            loop_index = loop_index+1
            if loop_index < count-1:
                prefix = f"--overwrite_{property_name}"
                if commandline_argument == prefix:
                    result = commandline_arguments[loop_index+1]
                    return result
        return result


    @GeneralUtilities.check_arguments
    def standardized_tasks_run_linting_for_flutter_project_in_common_project_structure(self, script_file: str,args: list[str]):
        pass  # TODO


    @GeneralUtilities.check_arguments
    def push_nuget_build_artifact(self, push_script_file: str, codeunitname: str, registry_address: str, repository_folder_name: str, api_key: str):
        # when pusing to "default public" nuget-server then use registry_address: "nuget.org"
        build_artifact_folder = GeneralUtilities.resolve_relative_path(f"../../Submodules/{repository_folder_name}/{codeunitname}/Other/Artifacts/BuildResult_NuGet", os.path.dirname(push_script_file))
        self.__sc.push_nuget_build_artifact(self.__sc.find_file_by_extension(build_artifact_folder, "nupkg"), registry_address, api_key)

    @GeneralUtilities.check_arguments
    def generate_certificate_for_development_purposes_for_external_service(self, service_folder: str, domain: str = None):
        testservice_name = os.path.basename(service_folder)
        ca_folder: str = None  # TODO
        self.__generate_certificate_for_development_purposes(testservice_name, os.path.join(service_folder, "Resources"), ca_folder, domain)

    @GeneralUtilities.check_arguments
    def generate_certificate_for_development_purposes_for_codeunit(self, codeunit_folder: str, domain: str = None):
        self.assert_is_codeunit_folder(codeunit_folder)
        codeunit_name = os.path.basename(codeunit_folder)
        self.ensure_product_resource_is_imported(codeunit_folder, "CA")
        ca_folder: str = os.path.join(codeunit_folder, "Other", "Resources", "CA")
        self.__generate_certificate_for_development_purposes(codeunit_name, os.path.join(codeunit_folder, "Other", "Resources"), ca_folder, domain)

    @GeneralUtilities.check_arguments
    def copy_product_resource_to_codeunit_resource_folder(self, codeunit_folder: str, resourcename: str) -> None:
        repository_folder = GeneralUtilities.resolve_relative_path(f"..", codeunit_folder)
        self.__sc.assert_is_git_repository(repository_folder)
        src_folder = GeneralUtilities.resolve_relative_path(f"Other/Resources/{resourcename}", repository_folder)
        GeneralUtilities.assert_condition(os.path.isdir(src_folder), f"Required product-resource {resourcename} does not exist. Expected folder: {src_folder}")
        trg_folder = GeneralUtilities.resolve_relative_path(f"Other/Resources/{resourcename}", codeunit_folder)
        GeneralUtilities.ensure_directory_does_not_exist(trg_folder)
        GeneralUtilities.ensure_directory_exists(trg_folder)
        GeneralUtilities.copy_content_of_folder(src_folder, trg_folder)

    @GeneralUtilities.check_arguments
    def ensure_product_resource_is_imported(self, codeunit_folder: str, product_resource_name: str) -> None:
        product_folder = os.path.dirname(codeunit_folder)
        source_folder = os.path.join(product_folder, "Other", "Resources", product_resource_name)
        target_folder = os.path.join(codeunit_folder, "Other", "Resources", product_resource_name)
        GeneralUtilities.ensure_directory_does_not_exist(target_folder)
        GeneralUtilities.ensure_directory_exists(target_folder)
        GeneralUtilities.copy_content_of_folder(source_folder, target_folder)




    @GeneralUtilities.check_arguments
    def create_release_starter_for_repository_in_standardized_format(self, create_release_file: str, logfile: str, addLogOverhead: bool):
        # hint: arguments can be overwritten by commandline_arguments
        folder_of_this_file = os.path.dirname(create_release_file)
        
        result = self.__sc.run_program("python", f"CreateRelease.py --overwrite_verbosity {str(int(self.__log.loglevel))}", folder_of_this_file, log_file=logfile, addLogOverhead=addLogOverhead, print_live_output=True, throw_exception_if_exitcode_is_not_zero=False)
        if result[0] != 0:
            raise ValueError(f"CreateRelease.py resulted in exitcode {result[0]}.")


    @GeneralUtilities.check_arguments
    def push_docker_build_artifact(self, push_artifacts_file: str, registry: str, push_readme: bool, repository_folder_name: str, remote_image_name: str = None) -> None:
        folder_of_this_file = os.path.dirname(push_artifacts_file)
        filename = os.path.basename(push_artifacts_file)
        codeunitname_regex: str = "([a-zA-Z0-9]+)"
        filename_regex: str = f"PushArtifacts\\.{codeunitname_regex}\\.py"
        if match := re.search(filename_regex, filename, re.IGNORECASE):
            codeunitname = match.group(1)
        else:
            raise ValueError(f"Expected push-artifacts-file to match the regex \"{filename_regex}\" where \"{codeunitname_regex}\" represents the codeunit-name.")
        
        repository_folder = GeneralUtilities.resolve_relative_path(f"..{os.path.sep}..{os.path.sep}Submodules{os.path.sep}{repository_folder_name}", folder_of_this_file)
        codeunit_folder = os.path.join(repository_folder, codeunitname)
        artifacts_folder = self.get_artifacts_folder(repository_folder, codeunitname)
        applicationimage_folder = os.path.join(artifacts_folder, "BuildResult_OCIImage")
        image_file = self.__sc.find_file_by_extension(applicationimage_folder, "tar")
        image_filename = os.path.basename(image_file)
        codeunit_version = self.get_version_of_codeunit(os.path.join(codeunit_folder, f"{codeunitname}.codeunit.xml"))
        if remote_image_name is None:
            remote_image_name = codeunitname
        remote_image_name = remote_image_name.lower()
        local_image_name = codeunitname.lower()
        remote_repo = f"{registry}/{remote_image_name}"
        remote_image_latest = f"{remote_repo}:latest"
        remote_image_version = f"{remote_repo}:{codeunit_version}"
        self.__log.log("Load image...")
        self.__sc.run_program("docker", f"load --input {image_filename}", applicationimage_folder)
        self.__log.log("Tag image...")
        self.__sc.run_program_with_retry("docker", f"tag {local_image_name}:{codeunit_version} {remote_image_latest}")
        self.__sc.run_program_with_retry("docker", f"tag {local_image_name}:{codeunit_version} {remote_image_version}")
        self.__log.log("Push image...")
        self.__sc.run_program_with_retry("docker", f"push {remote_image_latest}")
        self.__sc.run_program_with_retry("docker", f"push {remote_image_version}")
        if push_readme:
            self.__sc.run_program_with_retry("docker-pushrm", f"{remote_repo}", codeunit_folder)


    @GeneralUtilities.check_arguments
    def take_readmefile_from_main_readmefile_of_repository(self, common_tasks_scripts_file: str) -> None:
        folder_of_current_file = os.path.dirname(common_tasks_scripts_file)
        source_file = GeneralUtilities.resolve_relative_path("../../ReadMe.md", folder_of_current_file)
        target_file = GeneralUtilities.resolve_relative_path("../ReadMe.md", folder_of_current_file)
        GeneralUtilities.ensure_file_does_not_exist(target_file)
        shutil.copyfile(source_file, target_file)


    @GeneralUtilities.check_arguments
    def __suport_information_exists(self, repository_folder: str, version_of_product: str) -> bool:
        self.__sc.assert_is_git_repository(repository_folder)
        folder = os.path.join(repository_folder, "Other", "Resources", "Support")
        file = os.path.join(folder, "InformationAboutSupportedVersions.csv")
        if not os.path.isfile(file):
            return False
        entries = GeneralUtilities.read_csv_file(file, True)
        for entry in entries:
            if entry[0] == version_of_product:
                return True
        return False


    @GeneralUtilities.check_arguments
    def get_supported_versions(self, repository_folder: str, moment: datetime) -> list[tuple[str, datetime, datetime]]:
        self.__sc.assert_is_git_repository(repository_folder)
        result: list[tuple[str, datetime, datetime]] = list[tuple[str, datetime, datetime]]()
        for entry in self.get_versions(repository_folder):
            if entry[1] <= moment and moment <= entry[2]:
                result.append(entry)
        return result

    @GeneralUtilities.check_arguments
    def mark_current_version_as_supported(self, repository_folder: str, version_of_product: str, supported_from: datetime, supported_until: datetime):
        self.__sc.assert_is_git_repository(repository_folder)
        if self.__suport_information_exists(repository_folder, version_of_product):
            raise ValueError(f"Version-support for v{version_of_product} already defined.")
        folder = os.path.join(repository_folder, "Other", "Resources", "Support")
        GeneralUtilities.ensure_directory_exists(folder)
        file = os.path.join(folder, "InformationAboutSupportedVersions.csv")
        if not os.path.isfile(file):
            GeneralUtilities.ensure_file_exists(file)
            GeneralUtilities.append_line_to_file(file, "Version;SupportBegin;SupportEnd")
        GeneralUtilities.append_line_to_file(file, f"{version_of_product};{GeneralUtilities.datetime_to_string(supported_from)};{GeneralUtilities.datetime_to_string(supported_until)}")



    @GeneralUtilities.check_arguments
    def replace_common_variables_in_nuspec_file(self, codeunit_folder: str) -> None:
        self.assert_is_codeunit_folder(codeunit_folder)
        codeunit_name = os.path.basename(codeunit_folder)
        codeunit_version = self.get_version_of_codeunit_folder(codeunit_folder)
        nuspec_file = os.path.join(codeunit_folder, "Other", "Build", f"{codeunit_name}.nuspec")
        self.__sc.replace_version_in_nuspec_file(nuspec_file, codeunit_version)

    @GeneralUtilities.check_arguments
    def standardized_tasks_build_for_angular_codeunit(self, build_script_file: str, build_environment_target_type: str) -> None:
        build_script_folder = os.path.dirname(build_script_file)
        codeunit_folder = GeneralUtilities.resolve_relative_path("../..", build_script_folder)
        GeneralUtilities.ensure_directory_does_not_exist(f"{codeunit_folder}/.angular")
        self.standardized_tasks_build_for_node_codeunit(build_script_file, build_environment_target_type)

    @GeneralUtilities.check_arguments
    def standardized_tasks_linting_for_angular_codeunit(self, linting_script_file: str, build_environment_target_type: str) -> None:
        self.standardized_tasks_linting_for_node_codeunit(linting_script_file, build_environment_target_type)

    @GeneralUtilities.check_arguments
    def standardized_tasks_run_testcases_for_flutter_project_in_common_project_structure(self, script_file: str, args: list[str], package_name: str, build_environment_target_type: str, generate_badges: bool):
        codeunit_folder = GeneralUtilities.resolve_relative_path("../../..", script_file)
        repository_folder = GeneralUtilities.resolve_relative_path("..", codeunit_folder)
        codeunit_name = os.path.basename(codeunit_folder)
        src_folder = GeneralUtilities.resolve_relative_path(package_name, codeunit_folder)
        
        self.run_with_epew("flutter", "test --coverage", src_folder)
        test_coverage_folder_relative = "Other/Artifacts/TestCoverage"
        test_coverage_folder = GeneralUtilities.resolve_relative_path(test_coverage_folder_relative, codeunit_folder)
        GeneralUtilities.ensure_directory_exists(test_coverage_folder)
        coverage_file_relative = f"{test_coverage_folder_relative}/TestCoverage.xml"
        coverage_file = GeneralUtilities.resolve_relative_path(coverage_file_relative, codeunit_folder)
        self.run_with_epew("lcov_cobertura", f"coverage/lcov.info --base-dir . --excludes test --output ../{coverage_file_relative} --demangle", src_folder)

        # format correctly
        content = GeneralUtilities.read_text_from_file(coverage_file)
        content = re.sub('<![^<]+>', '', content)
        content = re.sub('\\\\', '/', content)
        content = re.sub('\\ name=\\"lib\\"', '', content)
        content = re.sub('\\ filename=\\"lib/', f' filename="{package_name}/lib/', content)
        GeneralUtilities.write_text_to_file(coverage_file, content)
        self.__testcoverage_for_flutter_project_merge_packages(coverage_file)
        self.__testcoverage_for_flutter_project_calculate_line_rate(coverage_file)

        self.run_testcases_common_post_task(repository_folder, codeunit_name, generate_badges, build_environment_target_type, args)


    @GeneralUtilities.check_arguments
    def standardized_tasks_run_testcases_for_angular_codeunit(self, runtestcases_script_file: str, build_environment_target_type: str, generate_badges: bool) -> None:

    @GeneralUtilities.check_arguments
    def copy_development_certificate_to_default_development_directory(self, codeunit_folder: str, build_environment: str, domain: str = None, certificate_resource_name: str = "DevelopmentCertificate") -> None:
        self.assert_is_codeunit_folder(codeunit_folder)
        if build_environment != "Productive":
            codeunit_name: str = os.path.basename(codeunit_folder)
            if domain is None:
                domain = f"{codeunit_name}.test.local".lower()

            src_folder = os.path.join(codeunit_folder, "Other", "Resources", certificate_resource_name)
            src_file_pfx = os.path.join(src_folder, f"{codeunit_name}{certificate_resource_name}.pfx")
            src_file_psw = os.path.join(src_folder, f"{codeunit_name}{certificate_resource_name}.password")

            trg_folder = os.path.join(codeunit_folder, "Other", "Workspace", "Configuration", "Certificates")
            trg_file_pfx = os.path.join(trg_folder, f"{domain}.pfx")
            trg_file_psw = os.path.join(trg_folder, f"{domain}.password")

            GeneralUtilities.assert_file_exists(src_file_pfx)
            GeneralUtilities.assert_file_exists(src_file_psw)
            GeneralUtilities.ensure_file_does_not_exist(trg_file_pfx)
            GeneralUtilities.ensure_file_does_not_exist(trg_file_psw)

            GeneralUtilities.ensure_directory_exists(trg_folder)

            GeneralUtilities.ensure_directory_exists(trg_folder)
            shutil.copyfile(src_file_pfx, trg_file_pfx)
            shutil.copyfile(src_file_psw, trg_file_psw)

    @GeneralUtilities.check_arguments
    def set_constants_for_certificate_public_information(self, codeunit_folder: str, source_constant_name: str = "DevelopmentCertificate", domain: str = None) -> None:
        """Expects a certificate-resource and generates a constant for its public information"""
        self.assert_is_codeunit_folder(codeunit_folder)
        certificate_file = os.path.join(codeunit_folder, "Other", "Resources", source_constant_name, f"{source_constant_name}.crt")
        with open(certificate_file, encoding="utf-8") as text_wrapper:
            certificate = crypto.load_certificate(crypto.FILETYPE_PEM, text_wrapper.read())
        certificate_publickey = crypto.dump_publickey(crypto.FILETYPE_PEM, certificate.get_pubkey()).decode("utf-8")
        self.set_constant(codeunit_folder, source_constant_name+"PublicKey", certificate_publickey)

    @GeneralUtilities.check_arguments
    def generate_constant_from_resource_by_extension(self, codeunit_folder: str, resource_name: str, extension: str, constant_name: str) -> None:
        self.assert_is_codeunit_folder(codeunit_folder)
        certificate_resource_folder = GeneralUtilities.resolve_relative_path(f"Other/Resources/{resource_name}", codeunit_folder)
        resource_file = self.__sc.find_file_by_extension(certificate_resource_folder, extension)
        resource_file_content = GeneralUtilities.read_binary_from_file(resource_file)
        resource_file_as_hex = resource_file_content.hex()
        self.set_constant(codeunit_folder, f"{resource_name}{constant_name}Hex", resource_file_as_hex)

    @GeneralUtilities.check_arguments
    def copy_constant_from_dependent_codeunit(self, codeunit_folder: str, constant_name: str, source_codeunit_name: str) -> None:
        self.assert_is_codeunit_folder(codeunit_folder)
        source_codeunit_folder: str = GeneralUtilities.resolve_relative_path(f"../{source_codeunit_name}", codeunit_folder)
        value = self.get_constant_value(source_codeunit_folder, constant_name)
        documentation = self.get_constant_documentation(source_codeunit_folder, constant_name)
        self.set_constant(codeunit_folder, constant_name, value, documentation)

    @GeneralUtilities.check_arguments
    def copy_resources_from_dependent_codeunit(self, codeunit_folder: str, resource_name: str, source_codeunit_name: str) -> None:
        self.assert_is_codeunit_folder(codeunit_folder)
        source_folder: str = GeneralUtilities.resolve_relative_path(f"../{source_codeunit_name}/Other/Resources/{resource_name}", codeunit_folder)
        target_folder: str = GeneralUtilities.resolve_relative_path(f"Other/Resources/{resource_name}", codeunit_folder)
        GeneralUtilities.ensure_directory_does_not_exist(target_folder)
        shutil.copytree(source_folder, target_folder)

    @GeneralUtilities.check_arguments
    def copy_resources_from_global_project_resources(self, codeunit_folder: str, resource_name: str) -> None:
        self.assert_is_codeunit_folder(codeunit_folder)
        source_folder: str = GeneralUtilities.resolve_relative_path(f"../Other/Resources/{resource_name}", codeunit_folder)
        target_folder: str = GeneralUtilities.resolve_relative_path(f"Other/Resources/{resource_name}", codeunit_folder)
        GeneralUtilities.ensure_directory_does_not_exist(target_folder)
        shutil.copytree(source_folder, target_folder)

    @GeneralUtilities.check_arguments
    def generate_openapi_file(self, buildscript_file: str, runtime: str, swagger_document_name: str = "APISpecification") -> None:
        self.__log.log("Generate OpenAPI-specification-file...")
        codeunitname = os.path.basename(str(Path(os.path.dirname(buildscript_file)).parent.parent.absolute()))
        repository_folder = str(Path(os.path.dirname(buildscript_file)).parent.parent.parent.absolute())
        codeunit_folder = os.path.join(repository_folder, codeunitname)
        self.assert_is_codeunit_folder(codeunit_folder)
        artifacts_folder = os.path.join(codeunit_folder, "Other", "Artifacts")
        GeneralUtilities.ensure_directory_exists(os.path.join(artifacts_folder, "APISpecification"))
        codeunit_version = self.get_version_of_codeunit_folder(codeunit_folder)

        versioned_api_spec_file = f"APISpecification/{codeunitname}.v{codeunit_version}.api.json"
        self.__sc.run_program("swagger", f"tofile --output {versioned_api_spec_file} BuildResult_DotNet_{runtime}/{codeunitname}.dll {swagger_document_name}", artifacts_folder)
        api_file: str = os.path.join(artifacts_folder, versioned_api_spec_file)
        shutil.copyfile(api_file, os.path.join(artifacts_folder, f"APISpecification/{codeunitname}.latest.api.json"))

        resources_folder = os.path.join(codeunit_folder, "Other", "Resources")
        GeneralUtilities.ensure_directory_exists(resources_folder)
        resources_apispec_folder = os.path.join(resources_folder, "APISpecification")
        GeneralUtilities.ensure_directory_exists(resources_apispec_folder)
        resource_target_file = os.path.join(resources_apispec_folder, f"{codeunitname}.api.json")
        GeneralUtilities.ensure_file_does_not_exist(resource_target_file)
        shutil.copyfile(api_file, resource_target_file)

        with open(api_file, encoding="utf-8") as api_file_content:
            reloaded_json = json.load(api_file_content)

            yamlfile1: str = str(os.path.join(artifacts_folder, f"APISpecification/{codeunitname}.v{codeunit_version}.api.yaml"))
            GeneralUtilities.ensure_file_does_not_exist(yamlfile1)
            GeneralUtilities.ensure_file_exists(yamlfile1)
            with open(yamlfile1, "w+", encoding="utf-8") as yamlfile:
                yaml.dump(reloaded_json, yamlfile, allow_unicode=True)

            yamlfile2: str = str(os.path.join(artifacts_folder, f"APISpecification/{codeunitname}.latest.api.yaml"))
            GeneralUtilities.ensure_file_does_not_exist(yamlfile2)
            shutil.copyfile(yamlfile1, yamlfile2)

            yamlfile3: str = str(os.path.join(resources_apispec_folder, f"{codeunitname}.api.yaml"))
            GeneralUtilities.ensure_file_does_not_exist(yamlfile3)
            shutil.copyfile(yamlfile1, yamlfile3)

    @GeneralUtilities.check_arguments
    def generate_api_client_from_dependent_codeunit_in_dotnet(self, file: str, name_of_api_providing_codeunit: str, base_namespace: str) -> None:
        codeunit_folder = GeneralUtilities.resolve_relative_path("../..", file)
        codeunit_name = os.path.basename(codeunit_folder)
        client_subpath = f"{codeunit_name}/APIClients/{name_of_api_providing_codeunit}"
        namespace = f"{base_namespace}.APIClients.{name_of_api_providing_codeunit}"
        target_subfolder_in_codeunit = client_subpath
        language = "csharp"
        additional_properties = f"--additional-properties packageName={namespace}"

        codeunit_folder = GeneralUtilities.resolve_relative_path("../..", file)
        self.ensure_openapigenerator_is_available(codeunit_folder)
        openapigenerator_jar_file = os.path.join(codeunit_folder, "Other", "Resources", "OpenAPIGenerator", "open-api-generator.jar")
        openapi_spec_file = os.path.join(codeunit_folder, "Other", "Resources", "DependentCodeUnits", name_of_api_providing_codeunit, "APISpecification", f"{name_of_api_providing_codeunit}.latest.api.json")
        target_folder = os.path.join(codeunit_folder, target_subfolder_in_codeunit)
        GeneralUtilities.ensure_directory_exists(target_folder)
        self.__sc.run_program("java", f'-jar {openapigenerator_jar_file} generate -i {openapi_spec_file} -g {language} -o {target_folder} --global-property supportingFiles --global-property models --global-property apis {additional_properties}', codeunit_folder)

        # move docs to correct folder
        target_folder_docs = os.path.join(target_folder, "docs")
        target_folder_docs_correct = os.path.join(codeunit_folder, "Other", "Reference", "ReferenceContent", f"{name_of_api_providing_codeunit}-API")
        GeneralUtilities.ensure_directory_does_not_exist(target_folder_docs_correct)
        GeneralUtilities.ensure_directory_exists(target_folder_docs_correct)
        GeneralUtilities.move_content_of_folder(target_folder_docs, target_folder_docs_correct)
        GeneralUtilities.ensure_directory_does_not_exist(target_folder_docs)

        code_folders = GeneralUtilities.get_direct_folders_of_folder(os.path.join(target_folder, "src"))

        # remove test-folder
        tests_folder = [x for x in code_folders if x.endswith(".Test")][0]
        GeneralUtilities.ensure_directory_does_not_exist(tests_folder)

        # move source to correct folder
        src_folder = [x for x in code_folders if not x.endswith(".Test")][0]
        target_folder_src = GeneralUtilities.resolve_relative_path("../..", src_folder)

        for targetfile in GeneralUtilities.get_direct_files_of_folder(target_folder_src):
            GeneralUtilities.ensure_file_does_not_exist(targetfile)
        for folder in GeneralUtilities.get_direct_folders_of_folder(target_folder_src):
            f = folder.replace("\\", "/")
            if not f.endswith("/.openapi-generator") and not f.endswith("/src"):
                GeneralUtilities.ensure_directory_does_not_exist(f)
        GeneralUtilities.ensure_directory_exists(target_folder_src)
        GeneralUtilities.move_content_of_folder(src_folder, target_folder_src)
        GeneralUtilities.ensure_directory_does_not_exist(src_folder)
        for targetfile in GeneralUtilities.get_direct_files_of_folder(target_folder_src):
            GeneralUtilities.ensure_file_does_not_exist(targetfile)



    @GeneralUtilities.check_arguments
    def build_dependent_code_units(self, repo_folder: str, codeunit_name: str, target_environmenttype: str, additional_arguments_file: str) -> None:
        verbosity = self.get_verbosity_from_commandline_arguments()
        codeunit_file = os.path.join(repo_folder, codeunit_name, codeunit_name + ".codeunit.xml")
        dependent_codeunits = self.get_dependent_code_units(codeunit_file)
        dependent_codeunits_folder = os.path.join(repo_folder, codeunit_name, "Other", "Resources", "DependentCodeUnits")
        GeneralUtilities.ensure_directory_does_not_exist(dependent_codeunits_folder)
        if 0 < len(dependent_codeunits):
            self.__log.log(f"Start building dependent codeunits for codeunit {codeunit_name}.")
        for dependent_codeunit in dependent_codeunits:
            self.__build_codeunit(os.path.join(repo_folder, dependent_codeunit), target_environmenttype, additional_arguments_file, False, False)
        if 0 < len(dependent_codeunits):
            self.__log.log(f"Finished building dependent codeunits for codeunit {codeunit_name}.")

    @GeneralUtilities.check_arguments
    def add_github_release(self, productname: str, projectversion: str, build_artifacts_folder: str, github_username: str, repository_folder: str, additional_attached_files: list[str]) -> None:
        self.__sc.assert_is_git_repository(repository_folder)
        self.__log.log(f"Create GitHub-release for {productname}...")
        verbosity = TasksForCommonProjectStructure.get_verbosity_from_commandline_arguments(commandline_arguments, 1)
        github_repo = f"{github_username}/{productname}"
        artifact_files = []
        codeunits = self.get_codeunits(repository_folder)
        for codeunit in codeunits:
            artifact_files.append(self.__sc.find_file_by_extension(f"{build_artifacts_folder}\\{productname}\\{projectversion}\\{codeunit}", "Productive.Artifacts.zip"))
        if additional_attached_files is not None:
            for additional_attached_file in additional_attached_files:
                artifact_files.append(additional_attached_file)
        changelog_file = os.path.join(repository_folder, "Other", "Resources", "Changelog", f"v{projectversion}.md")
        self.__sc.run_program_argsasarray("gh", ["release", "create", f"v{projectversion}", "--repo",  github_repo, "--notes-file", changelog_file, "--title", f"Release v{projectversion}"]+artifact_files)

    @GeneralUtilities.check_arguments
    def get_dependencies_which_are_ignored_from_updates(self, codeunit_folder: str, print_warnings_for_ignored_dependencies: bool) -> list[str]:
        self.assert_is_codeunit_folder(codeunit_folder)
        namespaces = {'cps': 'https://projects.aniondev.de/PublicProjects/Common/ProjectTemplates/-/tree/main/Conventions/RepositoryStructure/CommonProjectStructure', 'xsi': 'http://www.w3.org/2001/XMLSchema-instance'}
        codeunit_name = os.path.basename(codeunit_folder)
        codeunit_file = os.path.join(codeunit_folder, f"{codeunit_name}.codeunit.xml")
        root: etree._ElementTree = etree.parse(codeunit_file)
        ignoreddependencies = root.xpath('//cps:codeunit/cps:properties/cps:updatesettings/cps:ignoreddependencies/cps:ignoreddependency', namespaces=namespaces)
        result = [x.text.replace("\\n", GeneralUtilities.empty_string).replace("\\r", GeneralUtilities.empty_string).replace("\n", GeneralUtilities.empty_string).replace("\r", GeneralUtilities.empty_string).strip() for x in ignoreddependencies]
        if print_warnings_for_ignored_dependencies and len(result) > 0:
            self.__log.log(f"Codeunit {codeunit_name} contains the following dependencies which will are ignoed for automatic updates: "+', '.join(result), LogLevel.Warning)
        return result

    @GeneralUtilities.check_arguments
    def update_dependencies_of_typical_flutter_codeunit(self, update_script_file: str) -> None:
        codeunit_folder = GeneralUtilities.resolve_relative_path("..", os.path.dirname(update_script_file))
        ignored_dependencies = self.get_dependencies_which_are_ignored_from_updates(codeunit_folder, True)
        # TODO implement

    @GeneralUtilities.check_arguments
    def update_dependencies_of_typical_python_repository_requirements(self, repository_folder: str) -> None:

        development_requirements_file = os.path.join(repository_folder, "Other", "requirements.txt")
        if (os.path.isfile(development_requirements_file)):
            self.__sc.update_dependencies_of_python_in_requirementstxt_file(development_requirements_file, [])

    @GeneralUtilities.check_arguments
    def update_dependencies_of_typical_python_codeunit(self, update_script_file: str) -> None:
        codeunit_folder = GeneralUtilities.resolve_relative_path("..", os.path.dirname(update_script_file))
        ignored_dependencies = self.get_dependencies_which_are_ignored_from_updates(codeunit_folder, True)
        # TODO consider ignored_dependencies

        setup_cfg = os.path.join(codeunit_folder, "setup.cfg")
        if (os.path.isfile(setup_cfg)):
            self.__sc.update_dependencies_of_python_in_setupcfg_file(setup_cfg, ignored_dependencies)

        development_requirements_file = os.path.join(codeunit_folder, "requirements.txt")  # required for codeunits which contain python-code which need third-party dependencies
        if (os.path.isfile(development_requirements_file)):
            self.__sc.update_dependencies_of_python_in_requirementstxt_file(development_requirements_file, ignored_dependencies)

        development_requirements_file2 = os.path.join(codeunit_folder, "Other", "requirements.txt")  # required for codeunits which contain python-scripts which needs third-party dependencies
        if (os.path.isfile(development_requirements_file2)):
            self.__sc.update_dependencies_of_python_in_requirementstxt_file(development_requirements_file2, ignored_dependencies)

    @GeneralUtilities.check_arguments
    def update_dependencies_of_typical_dotnet_codeunit(self, update_script_file: str) -> None:
        codeunit_folder = GeneralUtilities.resolve_relative_path("..", os.path.dirname(update_script_file))
        ignored_dependencies = self.get_dependencies_which_are_ignored_from_updates(codeunit_folder, True)
        codeunit_name = os.path.basename(codeunit_folder)

        build_folder = os.path.join(codeunit_folder, "Other", "Build")
        self.__sc.run_program("python", "Build.py", build_folder)

        test_csproj_file = os.path.join(codeunit_folder, f"{codeunit_name}Tests", f"{codeunit_name}Tests.csproj")
        self.__sc.update_dependencies_of_dotnet_project(test_csproj_file, ignored_dependencies)
        csproj_file = os.path.join(codeunit_folder, codeunit_name, f"{codeunit_name}.csproj")
        self.__sc.update_dependencies_of_dotnet_project(csproj_file, ignored_dependencies)

    @GeneralUtilities.check_arguments
    def update_dependencies_of_package_json(self, folder: str) -> None:
        if self.is_codeunit_folder(folder):
            ignored_dependencies = self.get_dependencies_which_are_ignored_from_updates(folder, True)
        else:
            ignored_dependencies = []
        # TODO consider ignored_dependencies
        result = self.run_with_epew("npm", "outdated", folder, throw_exception_if_exitcode_is_not_zero=False)
        if result[0] == 0:
            return  # all dependencies up to date
        elif result[0] == 1:
            package_json_content = None
            package_json_file = f"{folder}/package.json"
            with open(package_json_file, "r", encoding="utf-8") as package_json_file_object:
                package_json_content = json.load(package_json_file_object)
                lines = GeneralUtilities.string_to_lines(result[1])[1:][:-1]
                for line in lines:
                    normalized_line_splitted = ' '.join(line.split()).split(" ")
                    package = normalized_line_splitted[0]
                    latest_version = normalized_line_splitted[3]
                    if package in package_json_content["dependencies"]:
                        package_json_content["dependencies"][package] = latest_version
                    if package in package_json_content["devDependencies"]:
                        package_json_content["devDependencies"][package] = latest_version
            with open(package_json_file, "w", encoding="utf-8") as package_json_file_object:
                json.dump(package_json_content, package_json_file_object, indent=4)
            self.do_npm_install(folder, True)
        else:
            self.__log.log("Update dependencies resulted in an error.", LogLevel.Error)

    @GeneralUtilities.check_arguments
    def start_local_test_service(self, file: str):
        example_folder = os.path.dirname(file)
        docker_compose_file = os.path.join(example_folder, "docker-compose.yml")
        for service in self.__sc.get_services_from_yaml_file(docker_compose_file):
            self.__sc.kill_docker_container(service)
        example_name = os.path.basename(example_folder)
        title = f"Test{example_name}"
        self.__sc.run_program("docker", f"compose -p {title.lower()} up --detach", example_folder, title=title)

    @GeneralUtilities.check_arguments
    def stop_local_test_service(self, file: str):
        example_folder = os.path.dirname(file)
        example_name = os.path.basename(example_folder)
        title = f"Test{example_name}"
        self.__sc.run_program("docker", f"compose -p {title.lower()} down", example_folder, title=title)

    @GeneralUtilities.check_arguments
    def start_dockerfile_example(self, current_file: str,remove_old_container: bool, remove_volumes_folder: bool, env_file: str) -> None:
        folder = os.path.dirname(current_file)
        example_name = os.path.basename(folder)
        oci_image_artifacts_folder = GeneralUtilities.resolve_relative_path("../../../../Artifacts/BuildResult_OCIImage", folder)
        image_filename = os.path.basename(self.__sc.find_file_by_extension(oci_image_artifacts_folder, "tar"))
        codeunit_name = os.path.basename(GeneralUtilities.resolve_relative_path("../../../../..", folder))
        if remove_old_container:
            docker_compose_file = f"{folder}/docker-compose.yml"
            container_names = []
            lines = GeneralUtilities.read_lines_from_file(docker_compose_file)
            for line in lines:
                if match := re.search("container_name:\\s*'?([^']+)'?", line):
                    container_names.append(match.group(1))
            self.__log.log(f"Ensure container of {docker_compose_file} do not exist...")
            for container_name in container_names:
                self.__log.log(f"Ensure container {container_name} does not exist...")
                self.__sc.run_program("docker", f"container rm -f {container_name}", oci_image_artifacts_folder, throw_exception_if_exitcode_is_not_zero=False)
        if remove_volumes_folder:
            volumes_folder = os.path.join(folder, "Volumes")
            self.__log.log(f"Ensure volumes-folder '{volumes_folder}' does not exist...")
            GeneralUtilities.ensure_directory_does_not_exist(volumes_folder)
            GeneralUtilities.ensure_directory_exists(volumes_folder)
        self.__log.log("Load docker-image...")
        self.__sc.run_program("docker", f"load -i {image_filename}", oci_image_artifacts_folder)
        docker_project_name = f"{codeunit_name}_{example_name}".lower()
        self.__log.log("Start docker-container...")
        argument = f"compose --project-name {docker_project_name}"
        if env_file is not None:
            argument = f"{argument} --env-file {env_file}"
        argument = f"{argument} up --detach"
        self.__sc.run_program("docker", argument, folder)

    @GeneralUtilities.check_arguments
    def ensure_env_file_is_generated(self, current_file: str, env_file_name: str, env_values: dict[str, str]):
        folder = os.path.dirname(current_file)
        env_file = os.path.join(folder, env_file_name)
        if not os.path.isfile(env_file):
            lines = []
            for key, value in env_values.items():
                lines.append(f"{key}={value}")
            GeneralUtilities.write_lines_to_file(env_file, lines)

    @GeneralUtilities.check_arguments
    def stop_dockerfile_example(self, current_file: str, remove_old_container: bool, remove_volumes_folder: bool) -> None:
        folder = os.path.dirname(current_file)
        example_name = os.path.basename(folder)
        codeunit_name = os.path.basename(GeneralUtilities.resolve_relative_path("../../../../..", folder))
        docker_project_name = f"{codeunit_name}_{example_name}".lower()
        self.__log.log("Stop docker-container...")
        self.__sc.run_program("docker", f"compose --project-name {docker_project_name} down", folder)

    @GeneralUtilities.check_arguments
    def create_artifact_for_development_certificate(self, codeunit_folder: str):
        self.assert_is_codeunit_folder(codeunit_folder)
        ce_source_folder = GeneralUtilities.resolve_relative_path("Other/Resources/DevelopmentCertificate", codeunit_folder)
        ca_source_folder = GeneralUtilities.resolve_relative_path("Other/Resources/CA", codeunit_folder)
        ce_target_folder = GeneralUtilities.resolve_relative_path("Other/Artifacts/DevelopmentCertificate", codeunit_folder)
        ca_target_folder = GeneralUtilities.resolve_relative_path("Other/Artifacts/CA", codeunit_folder)

        GeneralUtilities.ensure_directory_does_not_exist(ce_target_folder)
        GeneralUtilities.ensure_directory_exists(ce_target_folder)
        GeneralUtilities.copy_content_of_folder(ce_source_folder, ce_target_folder)
        GeneralUtilities.ensure_directory_does_not_exist(ca_target_folder)
        GeneralUtilities.ensure_directory_exists(ca_target_folder)
        GeneralUtilities.copy_content_of_folder(ca_source_folder, ca_target_folder)

    @GeneralUtilities.check_arguments
    def get_project_name(self, repository_folder: str) -> str:
        self.__sc.assert_is_git_repository(repository_folder)
        for file in GeneralUtilities.get_direct_files_of_folder(repository_folder):
            if file.endswith(".code-workspace"):
                return Path(file).stem
        raise ValueError(f'Project-name can not be calculated for repository "{repository_folder}"')

    def __check_target_environmenttype(self, target_environmenttype: str):
        allowed_values = list(self.get_default_target_environmenttype_mapping().values())
        if not (target_environmenttype in allowed_values):
            raise ValueError(f"Invalid target-environmenttype: '{target_environmenttype}'")

    @GeneralUtilities.check_arguments
    def build_codeunit(self, codeunit_folder: str, target_environmenttype: str = "QualityCheck", additional_arguments_file: str = None, is_pre_merge: bool = False, export_target_directory: str = None, assume_dependent_codeunits_are_already_built: bool = False) -> None:
        self.assert_is_codeunit_folder(codeunit_folder)
        codeunit_name = os.path.basename(codeunit_folder)
        repository_folder = os.path.dirname(codeunit_folder)
        self.build_specific_codeunits(repository_folder, [codeunit_name],  target_environmenttype, additional_arguments_file, is_pre_merge, export_target_directory, assume_dependent_codeunits_are_already_built,  False)

    @GeneralUtilities.check_arguments
    def __save_lines_of_code(self, repository_folder: str, project_version: str) -> None:
        loc = self.__sc.get_lines_of_code_with_default_excluded_patterns(repository_folder)
        loc_metric_folder = os.path.join(repository_folder, "Other", "Metrics")
        GeneralUtilities.ensure_directory_exists(loc_metric_folder)
        loc_metric_file = os.path.join(loc_metric_folder, "LinesOfCode.csv")
        GeneralUtilities.ensure_file_exists(loc_metric_file)
        old_lines = GeneralUtilities.read_lines_from_file(loc_metric_file)
        new_lines = []
        for line in old_lines:
            if not line.startswith(f"v{project_version};"):
                new_lines.append(line)
        new_lines.append(f"v{project_version};{loc}")
        GeneralUtilities.write_lines_to_file(loc_metric_file, new_lines)

    @GeneralUtilities.check_arguments
    def build_specific_codeunits(self, repository_folder: str, codeunits: list[str],  target_environmenttype: str = "QualityCheck", additional_arguments_file: str = None, is_pre_merge: bool = False, export_target_directory: str = None, assume_dependent_codeunits_are_already_built: bool = True , do_git_clean_when_no_changes: bool = False, note: str = None, check_for_new_files: bool = True) -> None:
        now_begin: datetime = GeneralUtilities.get_now()
        codeunits_list = "{"+", ".join(codeunits)+"}"
        self.__log.log(f"Start building codeunits {codeunits_list} in repository '{repository_folder}'...",LogLevel.Debug)
        self.__sc.assert_is_git_repository(repository_folder)
        self.__check_target_environmenttype(target_environmenttype)
        repository_folder = GeneralUtilities.resolve_relative_path_from_current_working_directory(repository_folder)
        repository_name = os.path.basename(repository_folder)
        contains_uncommitted_changes_at_begin = self.__sc.git_repository_has_uncommitted_changes(repository_folder)
        if contains_uncommitted_changes_at_begin:
            if is_pre_merge:
                raise ValueError(f'Repository "{repository_folder}" has uncommitted changes.')
        codeunit_subfolders = [os.path.join(repository_folder, codeunit) for codeunit in codeunits]
        codeunits_with_dependent_codeunits: dict[str, set[str]] = dict[str, set[str]]()

        for subfolder in codeunit_subfolders:
            codeunit_name: str = os.path.basename(subfolder)
            codeunit_file = os.path.join(subfolder, f"{codeunit_name}.codeunit.xml")
            GeneralUtilities.assert_condition(os.path.exists(codeunit_file), f"Codeunit-file '{codeunit_file}' does nost exist.")
            codeunits_with_dependent_codeunits[codeunit_name] = self.get_dependent_code_units(codeunit_file)
        sorted_codeunits = self.get_codeunits(repository_folder)
        sorted_codeunits = [codeunit for codeunit in sorted_codeunits if codeunit in codeunits]
        project_version = self.get_version_of_project(repository_folder)

        message = f"Build codeunits in product {repository_name}... (Started: {GeneralUtilities.datetime_to_string_for_logfile_entry(now_begin)})"
        if note is not None:
            message = f"{message} ({note})"
        self.__log.log(message)

        if len(sorted_codeunits) == 0:
            raise ValueError(f'No codeunit found in subfolders of "{repository_folder}".')
        else:
            self.__log.log(f"Attempt to build codeunits ({codeunits_list}) for project version {project_version} in the following order:")
            i = 0
            for codeunit in sorted_codeunits:
                i = i+1
                self.__log.log(f"{i}.: {codeunit}")
            for codeunit in sorted_codeunits:
                self.__log.log(GeneralUtilities.get_line())
                self.__build_codeunit(os.path.join(repository_folder, codeunit), target_environmenttype, additional_arguments_file, is_pre_merge, assume_dependent_codeunits_are_already_built)
            self.__log.log(GeneralUtilities.get_line())
        contains_uncommitted_changes_at_end = self.__sc.git_repository_has_uncommitted_changes(repository_folder)
        if contains_uncommitted_changes_at_end and (not is_pre_merge) and check_for_new_files:
            if contains_uncommitted_changes_at_begin:
                self.__log.log(f'There are still uncommitted changes in the repository "{repository_folder}".')
            else:
                message = f'Due to the build-process the repository "{repository_folder}" has new uncommitted changes.'
                if target_environmenttype == "Development":
                    self.__log.log(f"{message}", LogLevel.Warning)
                else:
                    raise ValueError(message)

        if export_target_directory is not None:
            project_name = self.get_project_name(repository_folder)
            for codeunit in sorted_codeunits:
                codeunit_version = self.get_version_of_codeunit_folder(os.path.join(repository_folder,  codeunit))
                artifacts_folder = os.path.join(repository_folder,  codeunit, "Other", "Artifacts")
                target_folder = os.path.join(export_target_directory, project_name, project_version, codeunit)
                GeneralUtilities.ensure_directory_does_not_exist(target_folder)
                GeneralUtilities.ensure_directory_exists(target_folder)
                filename_without_extension = f"{codeunit}.v{codeunit_version}.{target_environmenttype}.Artifacts"
                shutil.make_archive(filename_without_extension, 'zip', artifacts_folder)
                archive_file = os.path.join(os.getcwd(), f"{filename_without_extension}.zip")
                shutil.move(archive_file, target_folder)

        now_end: datetime = GeneralUtilities.get_now()
        message2 = f"Finished build codeunits in product {repository_name}. (Finished: {GeneralUtilities.datetime_to_string_for_logfile_entry(now_end)})"
        if note is not None:
            message2 = f"{message2} ({note})"
        self.__log.log(message2)

    @GeneralUtilities.check_arguments
    def __do_repository_checks(self, repository_folder: str, project_version: str) -> None:  # TDOO move this to a general project-specific (and codeunit-independent-script)
        self.__sc.assert_is_git_repository(repository_folder)
        self.__check_if_changelog_exists(repository_folder, project_version)
        self.__check_whether_security_txt_exists(repository_folder)
        self.__check_whether_general_reference_exists(repository_folder)
        self.__check_whether_workspace_file_exists(repository_folder)
        self.__check_for_staged_or_committed_ignored_files(repository_folder)

    @GeneralUtilities.check_arguments
    def __check_whether_general_reference_exists(self, repository_folder: str) -> None:
        GeneralUtilities.assert_file_exists(os.path.join(repository_folder, "Other", "Reference", "Reference.md"))

    @GeneralUtilities.check_arguments
    def __check_if_changelog_exists(self, repository_folder: str, project_version: str) -> None:
        self.__sc.assert_is_git_repository(repository_folder)
        changelog_folder = os.path.join(repository_folder, "Other", "Resources", "Changelog")
        changelog_file = os.path.join(changelog_folder, f"v{project_version}.md")
        if not os.path.isfile(changelog_file):
            raise ValueError(f"Changelog-file '{changelog_file}' does not exist. Try creating it using 'sccreatechangelogentry' for example.")

    @GeneralUtilities.check_arguments
    def __check_whether_security_txt_exists(self, repository_folder: str) -> None:
        security_txt_file_relative = ".well-known/security.txt"
        security_txt_file = GeneralUtilities.resolve_relative_path(security_txt_file_relative, repository_folder)
        if not os.path.isfile(security_txt_file):
            raise ValueError(f"The repository does not contain a '{security_txt_file_relative}'-file. See https://securitytxt.org/ for more information.")
        # TODO throw error if the date set in the file is expired
        # TODO write wartning if the date set in the file expires soon

    @GeneralUtilities.check_arguments
    def __check_for_staged_or_committed_ignored_files(self, repository_folder: str) -> None:
        for file in self.__sc.get_staged_or_committed_git_ignored_files(repository_folder):
            self.__log.log(f'Repository contains staged or committed file "{file}" which is git-ignored.', LogLevel.Warning)

    @GeneralUtilities.check_arguments
    def __check_whether_workspace_file_exists(self, repository_folder: str) -> None:
        count = 0
        for file in GeneralUtilities.get_direct_files_of_folder(repository_folder):
            if file.endswith(".code-workspace"):
                count = count + 1
        if count != 1:
            raise ValueError('The repository must contain exactly one ".code-workspace"-file on the top-level.')

    @GeneralUtilities.check_arguments
    def update_dependency_in_resources_folder(self, update_dependencies_file, dependency_name: str, latest_version_function: str) -> None:
        dependency_folder = GeneralUtilities.resolve_relative_path(f"../Resources/Dependencies/{dependency_name}", update_dependencies_file)
        version_file = os.path.join(dependency_folder, "Version.txt")
        version_file_exists = os.path.isfile(version_file)
        write_to_file = False
        if version_file_exists:
            current_version = GeneralUtilities.read_text_from_file(version_file)
            if current_version != latest_version_function:
                write_to_file = True
        else:
            GeneralUtilities.ensure_directory_exists(dependency_folder)
            GeneralUtilities.ensure_file_exists(version_file)
            write_to_file = True
        if write_to_file:
            GeneralUtilities.write_text_to_file(version_file, latest_version_function)

    @GeneralUtilities.check_arguments
    def load_deb_control_file_content(self, file: str, codeunitname: str, codeunitversion: str, installedsize: int, maintainername: str, maintaineremail: str, description: str,) -> str:
        content = GeneralUtilities.read_text_from_file(file)
        content = GeneralUtilities.replace_variable_in_string(content, "codeunitname", codeunitname)
        content = GeneralUtilities.replace_variable_in_string(content, "codeunitversion", codeunitversion)
        content = GeneralUtilities.replace_variable_in_string(content, "installedsize", str(installedsize))
        content = GeneralUtilities.replace_variable_in_string(content, "maintainername", maintainername)
        content = GeneralUtilities.replace_variable_in_string(content, "maintaineremail", maintaineremail)
        content = GeneralUtilities.replace_variable_in_string(content, "description", description)
        return content

    @GeneralUtilities.check_arguments
    def calculate_deb_package_size(self, binary_folder: str) -> int:
        size_in_bytes = 0
        for file in GeneralUtilities.get_all_files_of_folder(binary_folder):
            size_in_bytes = size_in_bytes+os.path.getsize(file)
        result = math.ceil(size_in_bytes/1024)
        return result

    @GeneralUtilities.check_arguments
    def create_deb_package_for_artifact(self, codeunit_folder: str, maintainername: str, maintaineremail: str, description: str) -> None:
        self.assert_is_codeunit_folder(codeunit_folder)
        codeunit_name = os.path.basename(codeunit_folder)
        binary_folder = GeneralUtilities.resolve_relative_path("Other/Artifacts/BuildResult_DotNet_linux-x64", codeunit_folder)
        deb_output_folder = GeneralUtilities.resolve_relative_path("Other/Artifacts/BuildResult_Deb", codeunit_folder)
        control_file = GeneralUtilities.resolve_relative_path("Other/Build/DebControlFile.txt", codeunit_folder)
        installedsize = self.calculate_deb_package_size(binary_folder)
        control_file_content = self.load_deb_control_file_content(control_file, codeunit_name, self.get_version_of_codeunit_folder(codeunit_folder), installedsize, maintainername, maintaineremail, description)
        self.__sc.create_deb_package(codeunit_name, binary_folder, control_file_content, deb_output_folder,  555)

    @GeneralUtilities.check_arguments
    def create_zip_file_for_artifact(self, codeunit_folder: str, artifact_source_name: str, name_of_new_artifact: str) -> None:
        self.assert_is_codeunit_folder(codeunit_folder)
        src_artifact_folder = GeneralUtilities.resolve_relative_path(f"Other/Artifacts/{artifact_source_name}", codeunit_folder)
        shutil.make_archive(name_of_new_artifact, 'zip', src_artifact_folder)
        archive_file = os.path.join(os.getcwd(), f"{name_of_new_artifact}.zip")
        target_folder = GeneralUtilities.resolve_relative_path(f"Other/Artifacts/{name_of_new_artifact}", codeunit_folder)
        GeneralUtilities.ensure_folder_exists_and_is_empty(target_folder)
        shutil.move(archive_file, target_folder)

    def generate_winget_zip_manifest(self, codeunit_folder: str, artifact_name_of_zip: str):
        self.assert_is_codeunit_folder(codeunit_folder)
        codeunit_version = self.get_version_of_codeunit_folder(codeunit_folder)
        build_folder = os.path.join(codeunit_folder, "Other", "Build")
        artifacts_folder = os.path.join(codeunit_folder, "Other", "Artifacts", artifact_name_of_zip)
        manifest_folder = os.path.join(codeunit_folder, "Other", "Artifacts", "WinGet-Manifest")
        GeneralUtilities.assert_folder_exists(artifacts_folder)
        artifacts_file = self.__sc.find_file_by_extension(artifacts_folder, "zip")
        winget_template_file = os.path.join(build_folder, "WinGet-Template.yaml")
        winget_manifest_file = os.path.join(manifest_folder, "WinGet-Manifest.yaml")
        GeneralUtilities.assert_file_exists(winget_template_file)
        GeneralUtilities.ensure_directory_exists(manifest_folder)
        GeneralUtilities.ensure_file_exists(winget_manifest_file)
        manifest_content = GeneralUtilities.read_text_from_file(winget_template_file)
        manifest_content = GeneralUtilities.replace_variable_in_string(manifest_content, "version", codeunit_version)
        manifest_content = GeneralUtilities.replace_variable_in_string(manifest_content, "sha256_hashvalue", GeneralUtilities.get_sha256_of_file(artifacts_file))
        GeneralUtilities.write_text_to_file(winget_manifest_file, manifest_content)


    @GeneralUtilities.check_arguments
    def repository_has_codeunits(self, repository: str, ignore_disabled_codeunits: bool = True) -> bool:
        return len(self.get_codeunits(repository, ignore_disabled_codeunits))

    def __ensure_changelog_file_is_added(self, repository_folder: str, version_of_project: str):
        changelog_file = os.path.join(repository_folder, "Other", "Resources", "Changelog", f"v{version_of_project}.md")
        if not os.path.isfile(changelog_file):
            GeneralUtilities.ensure_file_exists(changelog_file)
            GeneralUtilities.write_text_to_file(changelog_file, """# Release notes

## Changes

- Updated dependencies.
""")

    @GeneralUtilities.check_arguments
    def generic_update_dependencies(self, repository_folder: str):
        # Prepare
        self.__log.log("Update dependencies...")
        self.__sc.assert_is_git_repository(repository_folder)
        codeunits = self.get_codeunits(repository_folder)
        update_dependencies_script_filename = "UpdateDependencies.py"
        target_environmenttype = "QualityCheck"
        project_name: str = os.path.basename(repository_folder)
        GeneralUtilities.assert_condition(not self.__sc.git_repository_has_uncommitted_changes(repository_folder), "There are uncommitted changes in the repository.")
        self.build_codeunits(repository_folder, target_environmenttype=target_environmenttype, do_git_clean_when_no_changes_on_productive_build=True, note="Prepare dependency-update")  # Required because update dependencies is not always possible for not-buildet codeunits (depends on the programming language or package manager)

        # update dependencies of resources
        global_scripts_folder = os.path.join(repository_folder, "Other", "Scripts")
        if os.path.isfile(os.path.join(global_scripts_folder, update_dependencies_script_filename)):
            self.__sc.run_program("python", update_dependencies_script_filename, global_scripts_folder, print_live_output=True)
            version_of_project = self.get_version_of_project(repository_folder)
            self.__ensure_changelog_file_is_added(repository_folder, version_of_project)
            self.__log.log(f"Updated global dependencies of {project_name}.")
            self.build_codeunits(repository_folder, "QualityCheck", None, False, None, [], False, "Build codeunits due to updated product-wide dependencies")

        # update dependencies of codeunits
        for codeunit in codeunits:
            codeunit_file = os.path.join(repository_folder, codeunit, f"{codeunit}.codeunit.xml")
            codeunit_has_updatable_dependencies = self.codeunit_has_updatable_dependencies(codeunit_file)
            codeunit_folder: str = os.path.join(repository_folder, codeunit)
            self.build_codeunit(codeunit_folder, "QualityCheck", None, False, None, False, [])
            if codeunit_has_updatable_dependencies:
                codeunit_folder = os.path.join(repository_folder, codeunit)
                update_dependencies_script_folder = os.path.join(codeunit_folder, "Other")
                GeneralUtilities.ensure_directory_exists(os.path.join(update_dependencies_script_folder, "Resources", "CodeAnalysisResult"))
                self.__sc.run_program("python", update_dependencies_script_filename, update_dependencies_script_folder,  print_live_output=True)
                if self.__sc.git_repository_has_uncommitted_changes(repository_folder):
                    version_of_project = self.get_version_of_project(repository_folder)
                    self.__ensure_changelog_file_is_added(repository_folder, version_of_project)
                    self.__log.log(f"Updated dependencies in codeunit {codeunit}.")

        self.build_codeunits(repository_folder, "QualityCheck", None, False, None, [], False, "Build all codeunits due to updated dependencies")
        self.__sc.git_commit(repository_folder, "Updated dependencies")


    class UpdateHTTPDocumentationArguments:
        current_file: str
        product_name: str
        common_remote_name: str
        new_project_version: str
        reference_repository_name: str
        commandline_arguments: list[str]
        main_branch_name: str

        def __init__(self, current_file: str, product_name: str, common_remote_name: str, new_project_version: str, reference_repository_name: str):
            self.current_file = current_file
            self.product_name = product_name
            self.common_remote_name = common_remote_name
            self.new_project_version = new_project_version
            self.reference_repository_name = reference_repository_name
            self.commandline_arguments = commandline_arguments
            self.main_branch_name = "main"

    @GeneralUtilities.check_arguments
    def update_http_documentation(self, update_http_documentation_arguments: UpdateHTTPDocumentationArguments):
        self.__log.log(f"Update HTTP-documentation for for {update_http_documentation_arguments.product_name}...")
        folder_of_this_file = str(os.path.dirname(update_http_documentation_arguments.current_file))

        ref_repo = GeneralUtilities.resolve_relative_path(f"../../Submodules/{update_http_documentation_arguments.reference_repository_name}", folder_of_this_file)
        self.__sc.assert_is_git_repository(ref_repo)
        self.__sc.git_checkout(ref_repo, update_http_documentation_arguments.main_branch_name)

        # update reference
        target = os.path.join(ref_repo, "Reference", update_http_documentation_arguments.product_name)
        GeneralUtilities.ensure_directory_does_not_exist(target)
        shutil.copytree(GeneralUtilities.resolve_relative_path(f"../../Submodules/{update_http_documentation_arguments.product_name}Reference/ReferenceContent", folder_of_this_file), target)
        self.__sc.git_commit(ref_repo, f"Added reference of {update_http_documentation_arguments.product_name} v{update_http_documentation_arguments.new_project_version}")

        # Sync reference-repository
        self.__sc.git_fetch(ref_repo, update_http_documentation_arguments.common_remote_name)
        self.__sc.git_merge(ref_repo, update_http_documentation_arguments.common_remote_name+"/"+update_http_documentation_arguments.main_branch_name, update_http_documentation_arguments.main_branch_name)
        self.__sc.git_checkout(ref_repo, update_http_documentation_arguments.main_branch_name)
        self.__sc.git_push_with_retry(ref_repo, update_http_documentation_arguments.common_remote_name, update_http_documentation_arguments.main_branch_name, update_http_documentation_arguments.main_branch_name)
        self.__sc.git_commit(GeneralUtilities.resolve_relative_path("../..", folder_of_this_file), f"Updated content of {update_http_documentation_arguments.product_name} v{update_http_documentation_arguments.new_project_version} in {update_http_documentation_arguments.reference_repository_name}-submodule")

    @GeneralUtilities.check_arguments
    def install_requirementstxt_for_repository(self, repository_folde: str):
        self.__sc.install_requirementstxt_file(repository_folde+"/Other/requirements.txt")

    @GeneralUtilities.check_arguments
    def update_submodule(self, repository_folder: str, submodule_name: str, local_branch: str = "main", remote_branch: str = "main", remote: str = "origin"):
        submodule_folder = GeneralUtilities.resolve_relative_path("Other/Resources/Submodules/"+submodule_name, repository_folder)
        self.__sc.git_fetch(submodule_folder, remote)
        self.__sc.git_checkout(submodule_folder, local_branch)
        self.__sc.git_pull(submodule_folder, remote, local_branch, remote_branch, True)
        current_version = self.__sc.get_semver_version_from_gitversion(repository_folder)
        changelog_file = os.path.join(repository_folder, "Other", "Resources", "Changelog", f"v{current_version}.md")
        if (not os.path.isfile(changelog_file)):
            GeneralUtilities.ensure_file_exists(changelog_file)
            GeneralUtilities.write_text_to_file(changelog_file, """# Release notes

## Changes

- Updated geo-ip-database.
""")

    def set_latest_version_for_clone_repository_as_resource(self, resourcename: str, github_link: str, branch: str = "main"):
        current_file = str(Path(__file__).absolute())
        repository_folder = GeneralUtilities.resolve_relative_path("../../..", current_file)

        resrepo_commit_id_folder: str = os.path.join(repository_folder, "Other", "Resources", f"{resourcename}Version")
        resrepo_commit_id_file: str = os.path.join(resrepo_commit_id_folder, f"{resourcename}Version.txt")
        current_version: str = GeneralUtilities.read_text_from_file(resrepo_commit_id_file)

        stdOut = [l.split("\t") for l in GeneralUtilities.string_to_lines(self.__sc.run_program("git", f"ls-remote {github_link}")[1])]
        stdOut = [l for l in stdOut if l[1] == f"refs/heads/{branch}"]
        GeneralUtilities.assert_condition(len(stdOut) == 1)
        latest_version: str = stdOut[0][0]
        if current_version != latest_version:
            GeneralUtilities.write_text_to_file(resrepo_commit_id_file, latest_version)
